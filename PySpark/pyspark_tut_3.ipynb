{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyspark Handling Missing Values\n",
    "1) Dropping Columns\n",
    "2) Dropping Rows\n",
    "3) Various Parameter In Dropping functionalities\n",
    "4) Handling Missing values by Mean, MEdian And Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Tutorial_3').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Tutorial_3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f4dc58d820>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv('DataSet2.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Aayush|  24|         3| 25000|\n",
      "| Tripti|  22|         1| 20000|\n",
      "| Aditya|  25|         3| 30000|\n",
      "| Shivam|  25|         1| 30000|\n",
      "| Ashish|  25|         3| 28000|\n",
      "| Naincy|  25|         2| 32000|\n",
      "|Vaibhav|  26|         2| 35000|\n",
      "| Preeti|  26|         5| 40000|\n",
      "|Suruchi|  29|      NULL| 70000|\n",
      "| Chirag|  26|         4| 90000|\n",
      "| Anurag|NULL|        15|110000|\n",
      "|   NULL|  34|      NULL|  NULL|\n",
      "|   NULL|  36|      NULL|  NULL|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+\n",
      "|   Name| Age|Experience|\n",
      "+-------+----+----------+\n",
      "| Aayush|  24|         3|\n",
      "| Tripti|  22|         1|\n",
      "| Aditya|  25|         3|\n",
      "| Shivam|  25|         1|\n",
      "| Ashish|  25|         3|\n",
      "| Naincy|  25|         2|\n",
      "|Vaibhav|  26|         2|\n",
      "| Preeti|  26|         5|\n",
      "|Suruchi|  29|      NULL|\n",
      "| Chirag|  26|         4|\n",
      "| Anurag|NULL|        15|\n",
      "|   NULL|  34|      NULL|\n",
      "|   NULL|  36|      NULL|\n",
      "+-------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop columns\n",
    "df_spark.drop('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Aayush| 24|         3| 25000|\n",
      "| Tripti| 22|         1| 20000|\n",
      "| Aditya| 25|         3| 30000|\n",
      "| Shivam| 25|         1| 30000|\n",
      "| Ashish| 25|         3| 28000|\n",
      "| Naincy| 25|         2| 32000|\n",
      "|Vaibhav| 26|         2| 35000|\n",
      "| Preeti| 26|         5| 40000|\n",
      "| Chirag| 26|         4| 90000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop all rows wherever null is present\n",
    "# df_spark.dropna().show()\n",
    "df_spark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Aayush| 24|         3| 25000|\n",
      "| Tripti| 22|         1| 20000|\n",
      "| Aditya| 25|         3| 30000|\n",
      "| Shivam| 25|         1| 30000|\n",
      "| Ashish| 25|         3| 28000|\n",
      "| Naincy| 25|         2| 32000|\n",
      "|Vaibhav| 26|         2| 35000|\n",
      "| Preeti| 26|         5| 40000|\n",
      "| Chirag| 26|         4| 90000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop takes params as how , thresh and how\n",
    "df_spark.na.drop(how='any').show() # drop if any of row has null values.\n",
    "# df_spark.na.drop(how='all').show() # wherever all values are null, it'll drop that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Aayush|  24|         3| 25000|\n",
      "| Tripti|  22|         1| 20000|\n",
      "| Aditya|  25|         3| 30000|\n",
      "| Shivam|  25|         1| 30000|\n",
      "| Ashish|  25|         3| 28000|\n",
      "| Naincy|  25|         2| 32000|\n",
      "|Vaibhav|  26|         2| 35000|\n",
      "| Preeti|  26|         5| 40000|\n",
      "|Suruchi|  29|      NULL| 70000|\n",
      "| Chirag|  26|         4| 90000|\n",
      "| Anurag|NULL|        15|110000|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Threshold\n",
    "df_spark.na.drop(thresh=2).show() # drops where there is no atleast 2 non null values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Aayush| 24|         3| 25000|\n",
      "| Tripti| 22|         1| 20000|\n",
      "| Aditya| 25|         3| 30000|\n",
      "| Shivam| 25|         1| 30000|\n",
      "| Ashish| 25|         3| 28000|\n",
      "| Naincy| 25|         2| 32000|\n",
      "|Vaibhav| 26|         2| 35000|\n",
      "| Preeti| 26|         5| 40000|\n",
      "| Chirag| 26|         4| 90000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset\n",
    "df_spark.na.drop(how='any', subset=['Experience', 'Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|   NULL|  34|      NULL|  NULL|\n",
      "|   NULL|  36|      NULL|  NULL|\n",
      "| Aayush|  24|         3| 25000|\n",
      "| Aditya|  25|         3| 30000|\n",
      "| Anurag|NULL|        15|110000|\n",
      "| Ashish|  25|         3| 28000|\n",
      "| Chirag|  26|         4| 90000|\n",
      "| Naincy|  25|         2| 32000|\n",
      "| Preeti|  26|         5| 40000|\n",
      "| Shivam|  25|         1| 30000|\n",
      "|Suruchi|  29|      NULL| 70000|\n",
      "| Tripti|  22|         1| 20000|\n",
      "|Vaibhav|  26|         2| 35000|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort based on column\n",
    "df_spark.sort('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Aayush| 24|         3| 25000|\n",
      "| Tripti| 22|         1| 20000|\n",
      "| Aditya| 25|         3| 30000|\n",
      "| Shivam| 25|         1| 30000|\n",
      "| Ashish| 25|         3| 28000|\n",
      "| Naincy| 25|         2| 32000|\n",
      "|Vaibhav| 26|         2| 35000|\n",
      "| Preeti| 26|         5| 40000|\n",
      "|Suruchi| 29|         0| 70000|\n",
      "| Chirag| 26|         4| 90000|\n",
      "| Anurag|  0|        15|110000|\n",
      "|      0| 34|         0|     0|\n",
      "|      0| 36|         0|     0|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filling the missing values\n",
    "# df_spark.na.fill('0').show()\n",
    "# df_spark.na.fill(0, ['Experience', 'Age']).show()\n",
    "df_spark.na.fill({'Name': '0', 'Age': 0, 'Experience': 0, 'Salary': 0}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Aayush|  24|         3| 25000|\n",
      "| Tripti|  22|         1| 20000|\n",
      "| Aditya|  25|         3| 30000|\n",
      "| Shivam|  25|         1| 30000|\n",
      "| Ashish|  25|         3| 28000|\n",
      "| Naincy|  25|         2| 32000|\n",
      "|Vaibhav|  26|         2| 35000|\n",
      "| Preeti|  26|         5| 40000|\n",
      "|Suruchi|  29|      NULL| 70000|\n",
      "| Chirag|  26|         4| 90000|\n",
      "| Anurag|NULL|        15|110000|\n",
      "|   NULL|  34|      NULL|  NULL|\n",
      "|   NULL|  36|      NULL|  NULL|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# original df\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols=['Age', 'Experience', 'Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']], #strategy='mean'\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "| Aayush|  24|         3| 25000|         24|                 3|         25000|\n",
      "| Tripti|  22|         1| 20000|         22|                 1|         20000|\n",
      "| Aditya|  25|         3| 30000|         25|                 3|         30000|\n",
      "| Shivam|  25|         1| 30000|         25|                 1|         30000|\n",
      "| Ashish|  25|         3| 28000|         25|                 3|         28000|\n",
      "| Naincy|  25|         2| 32000|         25|                 2|         32000|\n",
      "|Vaibhav|  26|         2| 35000|         26|                 2|         35000|\n",
      "| Preeti|  26|         5| 40000|         26|                 5|         40000|\n",
      "|Suruchi|  29|      NULL| 70000|         29|                 3|         70000|\n",
      "| Chirag|  26|         4| 90000|         26|                 4|         90000|\n",
      "| Anurag|NULL|        15|110000|         26|                15|        110000|\n",
      "|   NULL|  34|      NULL|  NULL|         34|                 3|         46363|\n",
      "|   NULL|  36|      NULL|  NULL|         36|                 3|         46363|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputed_df = imputer.fit(df_spark).transform(df_spark).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
